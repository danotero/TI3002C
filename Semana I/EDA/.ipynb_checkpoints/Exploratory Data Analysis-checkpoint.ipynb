{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65557dfe",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis (EDA) is a phase of the Data Science Cycle in which we can attain a deeper understanding of the data: understanding interactions, detection of atypical data, data distribution, data visualization, among others. \n",
    "\n",
    "In this session, we will do some EDA of the `diabetes` dataset. For now, as usual, let us import some libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d96ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas                  as pd\n",
    "import numpy                   as np\n",
    "import matplotlib.pyplot       as plt\n",
    "import seaborn                 as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c69bbfd",
   "metadata": {},
   "source": [
    "Remember that this data was downloaded from this webpage: https://www.kaggle.com/vikasukani/diabetes-data-set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbef3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes-dataset.csv')\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd465a06",
   "metadata": {},
   "source": [
    "## Some statistics and skewness of a distribution\n",
    "\n",
    "One of the first things one could do is compute some statistics to comprehend a bit better the data. One good option is to use Panda's `describe` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96aac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34537b",
   "metadata": {},
   "source": [
    "Statistics such as standar deviation, mean, quantiles, and others, are provided by this method. One interesting thing is that these quantities can already tell us something about how a variable is distributed. For instance, a measure of **skewness** is the following formula:\n",
    "\n",
    "$$\\frac{\\mu-\\nu}{\\sigma}$$,\n",
    "\n",
    "where $\\nu$ is the median, also known as the second quantile. If this quantity is positive, this commonly indicates that the tail of the data is on the right side of the distribution; if said quantity is negative, then the tail is on the left side. If both $\\mu$ and $\\nu$ are equal, then we are dealing with a symmetric distribution.\n",
    "\n",
    "<img src=\"skewness.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "Notice that the well known variable `Pregnancies` has positive skewness. Let us verify that plotting a histogram of `Pregnancies` with Panda's `hist` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d203d25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes['Insulin'].hist(bins=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b09e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes['Pregnancies'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da7a02",
   "metadata": {},
   "source": [
    "What about `SkinThickness` and `BMI`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce40da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes[['SkinThickness', 'BMI']].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad97c1",
   "metadata": {},
   "source": [
    "Notice that the variable `BMI` posseses a close-to-symmetrical distribution, nevertheless, this measure of skewness fails assesssing how the variable `SkinThickness` is skewed. This is due to a large amount of registers with a value of zero. Let's correct that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6917e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes['SkinThickness'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec1ff09",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes[diabetes['SkinThickness'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f30ecd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes.loc[diabetes['SkinThickness'] > 0, 'SkinThickness'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15bf93d",
   "metadata": {},
   "source": [
    "What does the method `describe` has to say about this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21e7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes[(diabetes['SkinThickness'] > 0) & (diabetes['Insulin'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5ae50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes.loc[(diabetes['SkinThickness'] > 0) & (diabetes['Insulin'] > 0), 'SkinThickness'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c5692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.loc[(diabetes['SkinThickness'] > 0) & (diabetes['Insulin'] > 0), ['SkinThickness', 'Insulin']].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9102c94",
   "metadata": {},
   "source": [
    "Do you notice the difference? It seems that those zero values are \"making some noise.\" This could suggest that we might need a method to handle these zeros. \n",
    "\n",
    "Given the later, it is important to mention that the method for measuring skewness that we talked about is one of many, and not only that, it is not infallible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1acd25",
   "metadata": {},
   "source": [
    "## Scatter plots\n",
    "\n",
    "Scatter plots are a good way to visualize the relation between two variables. Let's assume we're interested in exploring how `BMI` and `BloodPressure` are related. Well, we will \"scatter them both.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53fa56c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='BMI', y='BloodPressure', data=diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa8eef",
   "metadata": {},
   "source": [
    "There is definitely a cluster, however, the plot shows that these two variables are correlated in a positive fashion: if one increases, the other goes up as well; if one goes down, the other does the same. In fact, I am not a doctor, but this makes sense: the higher the `BMI`, the higher the `BloodPressure`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76c881f",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "According to Wikipedia, \"in the broadest sense, correlation is any statistical association, though it actually refers to the degree to which a pair of variables are linearly related.\" So, if two variables have any type of statistical association with each other, they can be correlated, either positively or negatively. In fact, let's take a look at the following table:\n",
    "\n",
    "<img src=\"illuminati.jpg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "What do you make of this? Are we able to conclude that epidemic and pandemics are caused by advances in technology that works with electromagnetic waves?\n",
    "\n",
    "Well, of course not, these two variables might be correlated, but **correlation does not imply causation**. The moral of the story is that it is not wise to establish a cause-and-effect relationship based solely on correlation. Please, if you are reading this, just don't do it, this might lead you to conclude absurd things.\n",
    "\n",
    "However, stablishing correlations between a variable of interest and some predictors can be useful, as well as measuring the correlation between variables that we employ as predictors. A way to do this visually is with a **correlation matrix**. The following code does this for us with the variables of the `diabetes` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807bb2e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(diabetes.corr(), cmap=\"RdYlBu\", \n",
    "    annot=True, square=True,\n",
    "    vmin=-1, vmax=1, fmt=\"+.3f\")\n",
    "plt.title(\"Correlation matrix for the diabetes dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b09f7",
   "metadata": {},
   "source": [
    "## Detecting Outliers\n",
    "\n",
    "There are different techniques for detecting outliers, one of them being the **z-score**. This quantity is defined as follows:\n",
    "\n",
    "$$z=\\frac{x-\\mu}{\\sigma}$$,\n",
    "\n",
    "where $x$ is some observation. \n",
    "\n",
    "If a variable follows a normal distribution, or close to normal, then this score is worth using. The following image shows why:\n",
    "\n",
    "<img src=\"normal.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "The criterion for detecting outliers using the z-scores goes as this: if for a given observation $x$ the absolute value of its z-score is greater than 3, then x is an outlier.\n",
    "\n",
    "The `BMI` variable seems to follow a close to normal distribution, does it have any outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d3fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = diabetes['BMI'].std()\n",
    "mu = diabetes['BMI'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490d2f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes[diabetes['BMI'] > mu + 3 * sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98b1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes[diabetes['BMI'] < mu - 3 * sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d68be6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes['z-score'] = (diabetes['BMI'] - mu) / sigma\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f53131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes['z-score'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e4c88",
   "metadata": {},
   "source": [
    "### Boxplots\n",
    "\n",
    "**Boxplot** are another technique that help us to understand the distribution of a variable and are useful for detecting outliers as well. The following image shows the \"anatomy\" of a boxplot (in Spanish!):\n",
    "\n",
    "<img src=\"boxplot.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Eberything looks pretty clear, except for maximum and minimum non-atypical values. These are calculated as follows:\n",
    "\n",
    "$$\\text{Maximum non-atypical value}=Q_3+\\frac{3}{2}IQR$$\n",
    "$$\\text{Minimum non-atypical value}=Q_1-\\frac{3}{2}IQR$$,\n",
    "\n",
    "where $IQR=Q_3-Q_1$.\n",
    "\n",
    "This story would not be complete without a real boxplot, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903d8aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(y='BMI', data=diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y='Pregnancies', data=diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b6637",
   "metadata": {},
   "source": [
    "## Barplots\n",
    "\n",
    "Barplots are another tool that we can use to understand data better. For instance, say we want to see if there is a difference in the variable `BMI` of people with diabetes and people who dont't have this condition. We could do something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b5e2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=diabetes, x='Outcome', y='BMI', errorbar='sd')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "plt.title('Difference in BMI')\n",
    "plt.xlabel('Diabetes')\n",
    "plt.ylabel('BMI')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a78ca4",
   "metadata": {},
   "source": [
    "We can also use another variant of `barplot` known as `countplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=diabetes, x='Outcome')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "plt.title('Diabetes count')\n",
    "plt.xlabel('Diabetes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80a453",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "Another useful tool is the `groupy` method: if we wanna group our data by categories and then aggregate it with some function, this could help us to understand differences among several categories in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c89707",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.groupby(by='Outcome').mean()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
